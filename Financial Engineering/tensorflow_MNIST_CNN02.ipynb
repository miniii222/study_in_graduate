{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xdata = np.array([np.reshape(x,(28,28,1)) for x in mnist.train.images])\n",
    "test_xdata = np.array([np.reshape(x,(28,28,1)) for x in mnist.test.images])\n",
    "\n",
    "train_labels = mnist.train.labels\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1aab18bbb38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABgFJREFUeJzt3b2PTH0cxuE5j0UhXpINiXiJ0ClRaVRCIxovhUa5pUhIFIjINvwDCgW1QqnwD2whq9iViGiEhIRCBBGKo5UnOd9ZszNnZO/rau89OafwySl+ZqZp23YA5Plv2g8ATIf4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IdRMnzdrmsZ/J4QJa9u2WcnfefNDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDqJlpPwCTdeDAgXK/dOlSuR89erTcDx48WO5zc3Od28OHD8trmSxvfgglfgglfgglfgglfgglfgjVtG3b382apr+brSHr168v9/Pnz3duDx48KK/99etXuc/Pz5f7kSNHyn3Hjh2d27BjREbTtm2zkr/z5odQ4odQ4odQ4odQ4odQ4odQ4odQzvn/ARs2bCj327dvl/uVK1c6txcvXpTXXr58udyfPn1a7rt37x55n5mpP1H+48ePcn/27Fm5p3LOD5TED6HED6HED6HED6HED6HED6Gc8/dg48aN5X7//v1yv3DhQrkvLy93bhcvXiyvXVxcLPfV2rp1a+dWPfdgMBi8fPmy3I8fPz7SM611zvmBkvghlPghlPghlPghlPghlPghlJ/oHoNh5/i3bt0q92Hn+EtLS+V+4sSJzu3Dhw/ltZN29uzZzm3Xrl3ltT9//iz3TZs2lfu3b9/KPZ03P4QSP4QSP4QSP4QSP4QSP4QSP4Ryzj8Gp06dKverV6+W+9u3b8v95MmT5T7ts/zKtm3bRr728+fP5e4cf3W8+SGU+CGU+CGU+CGU+CGU+CGUo74Vmp2d7dzu3LlTXjvsSGpubq7c379/X+7TtHPnznI/c+ZMT0/C3/Lmh1Dih1Dih1Dih1Dih1Dih1Dih1DO+Veo+qnpffv2ldc+f/683J88eTLKI43FunXryn3YT3xfu3at3Pfv3/+3j0RPvPkhlPghlPghlPghlPghlPghlPghlHP+Huzdu7fcq5+xHgwGg+/fv49879OnT5f7uXPnyn3Lli3l/ubNm3Kvvutg2Fea/8tfSb4WePNDKPFDKPFDKPFDKPFDKPFDKPFDqKZt2/5u1jT93WzMmqbp3G7evFlee+PGjXE/zti8e/eu3O/evVvu9+7dK/c9e/Z0bq9fvy6vvX79ernPz8+Xe6q2bbv/sf7Bmx9CiR9CiR9CiR9CiR9CiR9CiR9COefvwbDPzA/7zP0w1efeHz16VF67sLCwqnuvxuLi4qquP3To0JieZG1xzg+UxA+hxA+hxA+hxA+hxA+hHPUxUZs3b+7clpeXy2s/ffpU7ocPHx7pmdY6R31ASfwQSvwQSvwQSvwQSvwQSvwQyk90M1Hbt2/v3Kqv9R4MBoPHjx+P+3H4gzc/hBI/hBI/hBI/hBI/hBI/hBI/hHLOz0QdO3Zs5Gs/fvw4xifh/7z5IZT4IZT4IZT4IZT4IZT4IZT4IZRzfiZqdnZ22o9AB29+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+COUjvUxN0zTlvrS01NOTZPLmh1Dih1Dih1Dih1Dih1Dih1Dih1DO+Zmatm3L/dWrVz09SSZvfgglfgglfgglfgglfgglfgglfgjlnJ+pGfZ5fibLmx9CiR9CiR9CiR9CiR9CiR9CiR9COednar58+VLuX79+7elJMnnzQyjxQyjxQyjxQyjxQyjxQ6hm2Ncnj/VmTdPfzSBU27Yr+qy0Nz+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+E6vXz/MC/w5sfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQv0GOPneB7AUXmUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(train_xdata[8,:,:].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of Conv layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.placeholder(tf.float32, shape = [None, 28,28,1])\n",
    "f1 = tf.Variable(tf.truncated_normal([4,4,1,32], stddev=0.01)) #filter size 4*4 / the number of filters 32\n",
    "conv1 = tf.nn.conv2d(input = x1,filter = f1,strides = [1,1,1,1], padding=\"SAME\")\n",
    "b1 = tf.Variable(tf.zeros([1,1,1,32]))\n",
    "\n",
    "a1 = tf.nn.relu(conv1+b1) #relu\n",
    "\n",
    "#pooling\n",
    "x2 = tf.nn.max_pool(a1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME') #N, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(32)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of Conv layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = tf.Variable(tf.truncated_normal([4,4,32,64], stddev=0.01))\n",
    "conv2 = tf.nn.conv2d(input = x2, filter = f2, strides = [1,1,1,1], padding = 'SAME')\n",
    "b2 = tf.Variable(tf.zeros([1,1,1,64]))\n",
    "\n",
    "a2 = tf.nn.relu(conv2+b2) #rellu\n",
    "\n",
    "#pooling \n",
    "x3 = tf.nn.max_pool(a2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(64)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "myshape = x3.shape\n",
    "final_shape = int(myshape[1]*myshape[2]*myshape[3])\n",
    "\n",
    "flat1 = tf.reshape(x3, [-1, final_shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(3136)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a1 = flat1\n",
    "w1 = tf.Variable(initial_value=tf.random_normal((final_shape, num_hidden), mean = 0, stddev = 1.0))\n",
    "b1 = tf.Variable(tf.zeros(num_hidden))\n",
    "z1 = tf.matmul(x_a1, w1) + b1\n",
    "x_a2 = tf.nn.sigmoid(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(128)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_a2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.Variable(initial_value=tf.random_normal((num_hidden, 10), mean = 0, stddev = 1.0))\n",
    "b2 = tf.Variable(tf.zeros([1, 10]))\n",
    "y = tf.nn.softmax(tf.matmul(x_a2,w2)+b2)\n",
    "t = tf.placeholder(tf.float32, shape=[None, 10]) #true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(t*tf.log(y), axis=1) )\n",
    "train_step = tf.train.AdadeltaOptimizer(1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs =12\n",
    "n_batches = 55000 // batch_size\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "init= tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# minibatch\n",
    "num_batch =  55000 // batch_size\n",
    "for epoch in range(2) :\n",
    "    X_ , Y_  = shuffle(X_train, y_train)\n",
    "    \n",
    "    for i in range(n_batches) :\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict = {x : X_[start:end, : ], t: Y_[start:end, :]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(t, 1), tf.argmax(y, 1))\n",
    "# print(sess.run(correct_prediction, feed_dict={t:train_labels, input1:train_xdata}))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# print(sess.run(accuracy, feed_dict={t:train_labels, input1:train_xdata}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(correct_prediction, feed_dict={t:test_labels, input1:test_xdata})\n",
    "print(sess.run(accuracy, feed_dict={t:test_labels, input1:test_xdata}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
